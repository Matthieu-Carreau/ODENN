{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook correspondant à la section 4.1.2 du rapport, pour la résolution des équations sur $M_x$ et $M_y$ couplées de la précession amortie :\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\frac{dM_x}{d\\tilde{t}} &= - M_y\\omega_z - \\lambda M_x M_z \\omega_z \\\\\n",
    "        \\frac{dM_y}{d\\tilde{t}} &= M_x\\omega_z - \\lambda M_y M_z \\omega_z\n",
    "    \\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial value for M = [Mx, My] vector\n",
    "M_0 = tf.constant([1,0], dtype='float32') \n",
    "#initial value for Mz\n",
    "M_z0 = tf.constant(0, dtype='float32') \n",
    "W = 2*np.pi\n",
    "lamb = -0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODE(Mx, My, Mz, W, lamb) :\n",
    "    dMx = -W*(My + lamb*tf.multiply(Mx,Mz_tensor))\n",
    "    dMy = W*(Mx - lamb*tf.multiply(My,Mz_tensor))\n",
    "    return dMx, dMy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40 #number of samples for the independant variable\n",
    "t_a = -1\n",
    "t_b = 1\n",
    "training_points = np.linspace(t_a,t_b,N)\n",
    "training_points = tf.convert_to_tensor(training_points, dtype=tf.float32)\n",
    "\n",
    "load_model = False\n",
    "load_filename = \"models/4_1_2_Mx_My\"\n",
    "save_model = False\n",
    "save_filename = \"models/4_1_2_Mx_My\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model for the evolution of Mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mz_model_filename = \"models/4_1_1_Mz\"\n",
    "Mz_model = tf.keras.models.load_model(Mz_model_filename)\n",
    "Mz_NN = Mz_model(training_points)\n",
    "\n",
    "Mz_tensor = M_z0+training_points*Mz_NN[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 1     # input layer number of neurons\n",
    "n_hidden_1 = 16 # 1st layer number of neurons\n",
    "n_output = 2    # output layer number of neurons\n",
    "\n",
    "#model definition :\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(n_hidden_1, activation=tf.nn.sigmoid, input_shape=(n_input,)),  \n",
    "  tf.keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "if load_model :\n",
    "    model = tf.keras.models.load_model(load_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, input_tensor, M_0, lamb, Mz_tensor):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        output = model(input_tensor)\n",
    "        Mx, My = M_0[0]+input_tensor*output[:,0], M_0[1]+input_tensor*output[:,1]\n",
    "\n",
    "    dMx = tape.gradient(Mx, input_tensor)\n",
    "    dMy = tape.gradient(My, input_tensor)\n",
    "\n",
    "    dMx_target, dMy_target = ODE(Mx, My, Mz_tensor, W, lamb)\n",
    "\n",
    "    ex = dMx - dMx_target\n",
    "    ey = dMy - dMy_target\n",
    "\n",
    "    return tf.reduce_mean(ex**2 + ey**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, input_tensor, M_0, lamb, Mz_tensor):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_function(model, input_tensor, M_0, lamb, Mz_tensor)\n",
    "\n",
    "    gradient = tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "    return loss_value, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "epochs = 2000\n",
    "display_step = min(max(1,epochs//100), 1000)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_displayed = []\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    loss_value, grads = grad(model, training_points, M_0, lamb, Mz_tensor)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    if epoch % display_step == 0 :\n",
    "        print(\"Loss after\",epoch,\"/\",epochs,\"epochs :\",loss_value.numpy())\n",
    "        losses.append(loss_value.numpy())\n",
    "        epochs_displayed.append(epoch)\n",
    "\n",
    "loss_value, grads = grad(model, training_points, M_0, lamb, Mz_tensor)\n",
    "print(\"Final loss after\",epochs,\"epochs :\",loss_value.numpy())\n",
    "losses.append(loss_value.numpy())\n",
    "epochs_displayed.append(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model :\n",
    "    model.save(save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_displayed, losses)\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the analytic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_points = np.linspace(t_a,t_b,200)\n",
    "plotting_points = tf.convert_to_tensor(plotting_points, dtype=tf.float32)\n",
    "\n",
    "\n",
    "#for plotting_points\n",
    "K = (M_z0-1) / (M_z0+1)\n",
    "exp_vector = tf.exp(-lamb*W*plotting_points)\n",
    "F = exp_vector*(K-1)/(K*exp_vector**2-1)\n",
    "\n",
    "Mx_ana =tf.multiply( F,(  tf.cos(W*plotting_points)*M_0[0] - tf.sin(W*plotting_points)*M_0[1]))\n",
    "My_ana = tf.multiply(F,( tf.sin(W*plotting_points)*M_0[0] + tf.cos(W*plotting_points)*M_0[1]))\n",
    "\n",
    "#for training_points\n",
    "K = (M_z0-1) / (M_z0+1)\n",
    "exp_vector = tf.exp(-lamb*W*training_points)\n",
    "F = exp_vector*(K-1)/(K*exp_vector**2-1)\n",
    "\n",
    "Mx_training =tf.multiply( F,(  tf.cos(W*training_points)*M_0[0] - tf.sin(W*training_points)*M_0[1]))\n",
    "My_training = tf.multiply(F,( tf.sin(W*training_points)*M_0[0] + tf.cos(W*training_points)*M_0[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimation and the analytic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network estimation\n",
    "output = model(plotting_points)\n",
    "Mx_NN, My_NN = M_0[0]+plotting_points*output[:,0], M_0[1]+plotting_points*output[:,1]\n",
    "\n",
    "\n",
    "#3D plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(        xs=Mx_NN,\n",
    "                ys=My_NN,\n",
    "                zs=plotting_points,\n",
    "                label='solution approchée')\n",
    "\n",
    "ax.plot(        xs=Mx_ana,\n",
    "                ys=My_ana,\n",
    "                zs=plotting_points,\n",
    "                label='solution exacte')\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(     xs=Mx_training,\n",
    "                ys=My_training,\n",
    "                zs=training_points,\n",
    "                color='red',\n",
    "                label='training points')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('résolution par réseau de neurones')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plotting_points, Mx_NN, label='solution approchée')\n",
    "plt.plot(plotting_points, Mx_ana, label='solution analytique')\n",
    "plt.scatter(training_points, Mx_training,color='red', label=\"points d'entraînement\")\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(plotting_points, My_NN, label='solution approchée')\n",
    "plt.plot(plotting_points, My_ana, label='solution analytique')\n",
    "plt.scatter(training_points, My_training,color='red', label=\"points d'entraînement\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if the norm of the magnetization found is conserved :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network estimation\n",
    "output = model(training_points)\n",
    "Mx_NN, My_NN = M_0[0]+training_points*output[:,0], M_0[1]+training_points*output[:,1]\n",
    "norm = tf.sqrt(Mx_NN**2 + My_NN**2 + Mz_tensor**2)\n",
    "\n",
    "plt.plot(training_points, norm, label='Norm of M over time')\n",
    "plt.scatter(training_points, norm, label='Norm of M over time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
